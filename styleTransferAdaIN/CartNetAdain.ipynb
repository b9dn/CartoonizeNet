{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNAge4bRTeZyb37KLWjxd9E"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"CRX5YjEXqrGI"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data\n","from torchvision import transforms\n","import torchvision.datasets as dset\n","import torchvision.utils as vutils\n","from torchvision import models\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch import sigmoid\n","import torch.nn.functional as F\n","from torch.utils import data\n","from pathlib import Path\n","from PIL import Image\n","from torchvision.utils import save_image"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"brlyeW2PtDhA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686414690351,"user_tz":-120,"elapsed":20374,"user":{"displayName":"Bogdan Bogdan","userId":"13678308282368438996"}},"outputId":"a76a892e-3656-433c-d700-5aee29dc4334"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!unzip -q '/content/drive/My Drive/coco2017.zip' -d '/content/coco2017'\n","!unzip -q '/content/drive/My Drive/coco2017_cart.zip' -d '/content/coco2017_cart'"],"metadata":{"id":"a35dP-QKtozv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HRe5_1rIbRDd","executionInfo":{"status":"ok","timestamp":1686414737477,"user_tz":-120,"elapsed":16,"user":{"displayName":"Bogdan Bogdan","userId":"13678308282368438996"}},"outputId":"153e8bf3-e2ad-4548-ae0f-36653251df03"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["coco2017  coco2017_cart  drive\tsample_data\n"]}]},{"cell_type":"code","source":["# foldery ze zdjeciami\n","dataroot_cart = \"/content/coco2017_cart/\"\n","dataroot_real = \"/content/coco2017/\"\n","\n","path_nets = \"/content/drive/My Drive/nets_cart_adain/\"\n","\n","workers = 0\n","\n","batch_size = 16\n","\n","image_size = 256\n","\n","lr = 0.0002\n","\n","beta1 = 0.5\n","\n","# dla ngpu 0 device = 'cpu'\n","ngpu = 1"],"metadata":{"id":"BqRbcsWhq2F3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n","if torch.cuda.is_available():\n","    print(torch.cuda.get_device_name())\n","print(device)"],"metadata":{"id":"PTO14wnJq3w2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686414737480,"user_tz":-120,"elapsed":13,"user":{"displayName":"Bogdan Bogdan","userId":"13678308282368438996"}},"outputId":"53faecf0-e739-4fd0-a802-8991405d1003"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tesla T4\n","cuda:0\n"]}]},{"cell_type":"code","source":["transformat = transforms.Compose([\n","    transforms.CenterCrop(256),\n","    transforms.ToTensor()\n","])\n","\n","# Obrazki komiksowe\n","dataset_cart = dset.ImageFolder(root=dataroot_cart, transform=transformat)\n","\n","dataloader_cart = torch.utils.data.DataLoader(dataset_cart, batch_size=batch_size,\n","                                            shuffle=False, num_workers=workers)\n","\n","# Obrazki prawdziwe\n","dataset_real = dset.ImageFolder(root=dataroot_real, transform=transformat)\n","\n","dataloader_real = torch.utils.data.DataLoader(dataset_real, batch_size=batch_size,\n","                                            shuffle=False, num_workers=workers)"],"metadata":{"id":"1UliHITAq65t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calc_mean_std(feat, eps=1e-5):\n","    # eps is a small value added to the variance to avoid divide-by-zero.\n","    size = feat.size()\n","    assert (len(size) == 4)\n","    N, C = size[:2]\n","    feat_var = feat.view(N, C, -1).var(dim=2) + eps\n","    feat_std = feat_var.sqrt().view(N, C, 1, 1)\n","    feat_mean = feat.view(N, C, -1).mean(dim=2).view(N, C, 1, 1)\n","    return feat_mean, feat_std\n","\n","\n","def adaptive_instance_normalization(content_feat, style_feat):\n","    assert (content_feat.size()[:2] == style_feat.size()[:2])\n","    size = content_feat.size()\n","    style_mean, style_std = calc_mean_std(style_feat)\n","    content_mean, content_std = calc_mean_std(content_feat)\n","\n","    normalized_feat = (content_feat - content_mean.expand(\n","        size)) / content_std.expand(size)\n","    return normalized_feat * style_std.expand(size) + style_mean.expand(size)\n","\n","\n","def _calc_feat_flatten_mean_std(feat):\n","    # takes 3D feat (C, H, W), return mean and std of array within channels\n","    assert (feat.size()[0] == 3)\n","    assert (isinstance(feat, torch.FloatTensor))\n","    feat_flatten = feat.view(3, -1)\n","    mean = feat_flatten.mean(dim=-1, keepdim=True)\n","    std = feat_flatten.std(dim=-1, keepdim=True)\n","    return feat_flatten, mean, std\n","\n","\n","def _mat_sqrt(x):\n","    U, D, V = torch.svd(x)\n","    return torch.mm(torch.mm(U, D.pow(0.5).diag()), V.t())\n","\n","\n","def coral(source, target):\n","    # assume both source and target are 3D array (C, H, W)\n","    # Note: flatten -> f\n","\n","    source_f, source_f_mean, source_f_std = _calc_feat_flatten_mean_std(source)\n","    source_f_norm = (source_f - source_f_mean.expand_as(\n","        source_f)) / source_f_std.expand_as(source_f)\n","    source_f_cov_eye = \\\n","        torch.mm(source_f_norm, source_f_norm.t()) + torch.eye(3)\n","\n","    target_f, target_f_mean, target_f_std = _calc_feat_flatten_mean_std(target)\n","    target_f_norm = (target_f - target_f_mean.expand_as(\n","        target_f)) / target_f_std.expand_as(target_f)\n","    target_f_cov_eye = \\\n","        torch.mm(target_f_norm, target_f_norm.t()) + torch.eye(3)\n","\n","    source_f_norm_transfer = torch.mm(\n","        _mat_sqrt(target_f_cov_eye),\n","        torch.mm(torch.inverse(_mat_sqrt(source_f_cov_eye)),\n","                 source_f_norm)\n","    )\n","\n","    source_f_transfer = source_f_norm_transfer * \\\n","                        target_f_std.expand_as(source_f_norm) + \\\n","                        target_f_mean.expand_as(source_f_norm)\n","\n","    return source_f_transfer.view(source.size())\n"],"metadata":{"id":"6xMkUnsbTE8s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["decoder = nn.Sequential(\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(512, 256, (3, 3)),\n","    nn.ReLU(),\n","    nn.Upsample(scale_factor=2, mode='nearest'),\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(256, 256, (3, 3)),\n","    nn.ReLU(),\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(256, 256, (3, 3)),\n","    nn.ReLU(),\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(256, 256, (3, 3)),\n","    nn.ReLU(),\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(256, 128, (3, 3)),\n","    nn.ReLU(),\n","    nn.Upsample(scale_factor=2, mode='nearest'),\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(128, 128, (3, 3)),\n","    nn.ReLU(),\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(128, 64, (3, 3)),\n","    nn.ReLU(),\n","    nn.Upsample(scale_factor=2, mode='nearest'),\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(64, 64, (3, 3)),\n","    nn.ReLU(),\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(64, 3, (3, 3)),\n","    nn.Sigmoid()\n",")\n","\n","vgg = nn.Sequential(\n","    nn.Conv2d(3, 3, (1, 1)),\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(3, 64, (3, 3)),\n","    nn.ReLU(),  # relu1-1\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(64, 64, (3, 3)),\n","    nn.ReLU(),  # relu1-2\n","    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(64, 128, (3, 3)),\n","    nn.ReLU(),  # relu2-1\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(128, 128, (3, 3)),\n","    nn.ReLU(),  # relu2-2\n","    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(128, 256, (3, 3)),\n","    nn.ReLU(),  # relu3-1\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(256, 256, (3, 3)),\n","    nn.ReLU(),  # relu3-2\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(256, 256, (3, 3)),\n","    nn.ReLU(),  # relu3-3\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(256, 256, (3, 3)),\n","    nn.ReLU(),  # relu3-4\n","    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(256, 512, (3, 3)),\n","    nn.ReLU(),  # relu4-1, this is the last layer used\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(512, 512, (3, 3)),\n","    nn.ReLU(),  # relu4-2\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(512, 512, (3, 3)),\n","    nn.ReLU(),  # relu4-3\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(512, 512, (3, 3)),\n","    nn.ReLU(),  # relu4-4\n","    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(512, 512, (3, 3)),\n","    nn.ReLU(),  # relu5-1\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(512, 512, (3, 3)),\n","    nn.ReLU(),  # relu5-2\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(512, 512, (3, 3)),\n","    nn.ReLU(),  # relu5-3\n","    nn.ReflectionPad2d((1, 1, 1, 1)),\n","    nn.Conv2d(512, 512, (3, 3)),\n","    nn.ReLU()  # relu5-4\n",")"],"metadata":{"id":"POO2acTpTRZ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Net(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(Net, self).__init__()\n","        enc_layers = list(encoder.children())\n","        self.enc_1 = nn.Sequential(*enc_layers[:4])  # input -> relu1_1\n","        self.enc_2 = nn.Sequential(*enc_layers[4:11])  # relu1_1 -> relu2_1\n","        self.enc_3 = nn.Sequential(*enc_layers[11:18])  # relu2_1 -> relu3_1\n","        self.enc_4 = nn.Sequential(*enc_layers[18:31])  # relu3_1 -> relu4_1\n","        self.decoder = decoder\n","        self.mse_loss = nn.MSELoss()\n","\n","        # fix the encoder\n","        for name in ['enc_1', 'enc_2', 'enc_3', 'enc_4']:\n","            for param in getattr(self, name).parameters():\n","                param.requires_grad = False\n","\n","    # extract relu1_1, relu2_1, relu3_1, relu4_1 from input image\n","    def encode_with_intermediate(self, input):\n","        results = [input]\n","        for i in range(4):\n","            func = getattr(self, 'enc_{:d}'.format(i + 1))\n","            results.append(func(results[-1]))\n","        return results[1:]\n","\n","    # extract relu4_1 from input image\n","    def encode(self, input):\n","        for i in range(4):\n","            input = getattr(self, 'enc_{:d}'.format(i + 1))(input)\n","        return input\n","\n","    def calc_content_loss(self, input, target):\n","        assert (input.size() == target.size())\n","        assert (target.requires_grad is False)\n","        return self.mse_loss(input, target)\n","\n","    def calc_style_loss(self, input, target):\n","        assert (input.size() == target.size())\n","        assert (target.requires_grad is False)\n","        input_mean, input_std = calc_mean_std(input)\n","        target_mean, target_std = calc_mean_std(target)\n","        return self.mse_loss(input_mean, target_mean) + \\\n","               self.mse_loss(input_std, target_std)\n","\n","    def forward(self, content, style, alpha=1.0):\n","        assert 0 <= alpha <= 1\n","        style_feats = self.encode_with_intermediate(style)\n","        content_feat = self.encode(content)\n","        t = adaptive_instance_normalization(content_feat, style_feats[-1])\n","        t = alpha * t + (1 - alpha) * content_feat\n","\n","        g_t = self.decoder(t)\n","        g_t_feats = self.encode_with_intermediate(g_t)\n","\n","        loss_c = self.calc_content_loss(g_t_feats[-1], t)\n","        loss_s = self.calc_style_loss(g_t_feats[0], style_feats[0])\n","        for i in range(1, 4):\n","            loss_s += self.calc_style_loss(g_t_feats[i], style_feats[i])\n","        return loss_c, loss_s"],"metadata":{"id":"s33c2yfxTrWA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# do testowania\n","def test_transform(size, crop):\n","    transform_list = []\n","    if size != 0:\n","        transform_list.append(transforms.Resize(size))\n","    if crop:\n","        transform_list.append(transforms.CenterCrop(size))\n","    transform_list.append(transforms.ToTensor())\n","    transform = transforms.Compose(transform_list)\n","    return transform\n","\n","\n","def style_transfer(vgg, decoder, content, style, alpha=1.0,\n","                   interpolation_weights=None):\n","    assert (0.0 <= alpha <= 1.0)\n","    content_f = vgg(content)\n","    style_f = vgg(style)\n","    if interpolation_weights:\n","        _, C, H, W = content_f.size()\n","        feat = torch.FloatTensor(1, C, H, W).zero_().to(device)\n","        base_feat = adaptive_instance_normalization(content_f, style_f)\n","        for i, w in enumerate(interpolation_weights):\n","            feat = feat + w * base_feat[i:i + 1]\n","        content_f = content_f[0:1]\n","    else:\n","        feat = adaptive_instance_normalization(content_f, style_f)\n","    feat = feat * alpha + content_f * (1 - alpha)\n","    return decoder(feat)"],"metadata":{"id":"1yYiC-XaVwF2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["content = '/content/drive/My Drive/adaintest/content/dog.jpg'\n","content_dir = None\n","style = '/content/drive/My Drive/comic.jpg'\n","style_dir = None\n","vgg_path = '/content/drive/My Drive/adain_models/vgg_normalised.pth'\n","decoder_path = '/content/drive/My Drive/adain_models/decoder.pth'\n","content_size = 0\n","style_size = 0\n","crop = False\n","save_ext = '.jpg'\n","output = '/content/drive/My Drive/adaintest/output'\n","preserve_color = True\n","alpha = 1.0\n","style_interpolation_weights = ''"],"metadata":{"id":"k2CG7Tim-YD5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def print_photos(phot, phot_cart=None, nrow=8):\n","    if phot_cart is None:\n","        plt.imshow(np.transpose(vutils.make_grid(phot, normalize=True, nrow=nrow).cpu(), (1, 2, 0)))\n","    else:\n","        plt.imshow(np.transpose(vutils.make_grid([*phot,*phot_cart], normalize=True, nrow=nrow).cpu(), (1, 2, 0)))\n","    plt.show()\n","\n","\n","def save_net(net, path):\n","    #torch.save(net, path)\n","    torch.save(net.state_dict(), path + \"_state\")\n","\n"],"metadata":{"id":"sgfme1vPrv1_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = nn.BCELoss()\n","\n","optimizer = optim.Adam(decoder.parameters(), lr=lr, betas=(beta1, 0.999))\n","\n","decoder.load_state_dict(torch.load(decoder_path))\n","vgg.load_state_dict(torch.load(vgg_path))\n","vgg = nn.Sequential(*list(vgg.children())[:31])\n","\n","vgg.to(device)\n","decoder.to(device)\n","\n","vgg.eval()\n","decoder.train()"],"metadata":{"id":"Ohx5VS8Vrd2N","executionInfo":{"status":"ok","timestamp":1686414804909,"user_tz":-120,"elapsed":8411,"user":{"displayName":"Bogdan Bogdan","userId":"13678308282368438996"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c3832121-e31d-4f48-bdc6-77ac504a6876"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): ReflectionPad2d((1, 1, 1, 1))\n","  (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n","  (2): ReLU()\n","  (3): Upsample(scale_factor=2.0, mode='nearest')\n","  (4): ReflectionPad2d((1, 1, 1, 1))\n","  (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n","  (6): ReLU()\n","  (7): ReflectionPad2d((1, 1, 1, 1))\n","  (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n","  (9): ReLU()\n","  (10): ReflectionPad2d((1, 1, 1, 1))\n","  (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n","  (12): ReLU()\n","  (13): ReflectionPad2d((1, 1, 1, 1))\n","  (14): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n","  (15): ReLU()\n","  (16): Upsample(scale_factor=2.0, mode='nearest')\n","  (17): ReflectionPad2d((1, 1, 1, 1))\n","  (18): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n","  (19): ReLU()\n","  (20): ReflectionPad2d((1, 1, 1, 1))\n","  (21): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (22): ReLU()\n","  (23): Upsample(scale_factor=2.0, mode='nearest')\n","  (24): ReflectionPad2d((1, 1, 1, 1))\n","  (25): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (26): ReLU()\n","  (27): ReflectionPad2d((1, 1, 1, 1))\n","  (28): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1))\n","  (29): Sigmoid()\n",")"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["n_epoch = 51\n","net_number = 1\n","save_period = 300\n","print_period = 300\n","\n","tf = test_transform(256, True)\n","style_img = tf(Image.open(str(style)))\n","style_img = style_img.unsqueeze(0)\n","\n","for epoch in range(n_epoch):\n","\n","    n_iters = len(dataloader_cart) if len(dataloader_cart) < len(dataloader_real) else len(dataloader_real)\n","\n","    for (i, cart_batch), real_batch in zip(enumerate(dataloader_cart, 1),\n","                                    iter(dataloader_real)):\n","\n","        # ladowanie komiksowych obrazkow\n","        cart_images = cart_batch[0].to(device)\n","        cart_size = cart_images.size(0)\n","\n","        # ladowanie prawdziwych zdjec\n","        real_images = real_batch[0].to(device)\n","        real_size = real_images.size(0)\n","\n","        # powielone zdjecie stylu\n","        style_batch = style_img.repeat(real_images.size(0), 1, 1, 1).to(device)\n","\n","        ####################################\n","        # Training\n","\n","        optimizer.zero_grad()\n","\n","        with torch.no_grad():\n","            content_f = vgg(real_images)\n","            style_f = vgg(style_batch)\n","            feat = adaptive_instance_normalization(content_f, style_f)\n","            feat = feat * alpha + content_f * (1 - alpha)\n","        output = decoder(feat)\n","\n","        err = criterion(output, cart_images)\n","        err.backward()\n","\n","        optimizer.step()\n","\n","        if i % print_period == 0 or i == 2:\n","            print_photos(real_images[:8], output[:8])\n","        if i % 35 == 0:\n","            print(\"epoch - \", epoch, \": \", i, \"/\", n_iters, \"   err - \", err.item())\n","        if (i == n_iters - 1) or i % save_period == 0:\n","            save_net(decoder, path_nets + \"net\" + str(net_number))\n","            net_number += 1\n"],"metadata":{"id":"VTIGguoVrgWf","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1_aw5tlXpU1L2wS1iw6zxDjDeEg-kzE4y"},"executionInfo":{"status":"error","timestamp":1686421517639,"user_tz":-120,"elapsed":4749645,"user":{"displayName":"Bogdan Bogdan","userId":"13678308282368438996"}},"outputId":"66875a05-d6a8-4e98-d2ee-4fa4a2128ffa"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["#del real_images\n","#del cart_images\n","#del output\n","torch.cuda.empty_cache()\n","optimizer.zero_grad()"],"metadata":{"id":"YfytbuekpgG9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drive.flush_and_unmount()"],"metadata":{"id":"zUgcIduZZpsd"},"execution_count":null,"outputs":[]}]}